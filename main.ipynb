{"cells":[{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["!rm -rdf __pycache__ *.pyc\n","\n","import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from bnn import BayesianNeuralNetwork, KLDivergence\n","from torchvision import datasets, transforms\n","\n","epochs = 5\n","batch_size = 256\n","learning_rate = 1e-3\n","validation_frequency = 100\n","samples = 10\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize((0.1307,), (0.3081,))\n","                   ])),\n","    batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])),\n","    batch_size=batch_size, shuffle=True)\n","\n","n_batches = int(np.ceil(len(train_loader.dataset) / batch_size))\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["model = BayesianNeuralNetwork(784, 10).to(device)\n","loss_function = torch.nn.CrossEntropyLoss()\n","kld = KLDivergence(n_batches)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def plot_lines(df, columns, colors, ax, alpha=0.25, show_range=False, window_size=1):\n","    for color, column in zip(colors, columns):\n","        agg_df = df.groupby('epoch')[column]\n","\n","        if window_size > 1:\n","            agg_df = agg_df.mean().rolling(window_size, min_periods=1)\n","\n","        means = agg_df.mean()\n","        ax.plot(np.arange(len(means)), means, c=color)\n","\n","        if show_range:\n","            mins = agg_df.min()\n","            maxs = agg_df.max()\n","            ax.fill_between(x=np.arange(len(means)),\n","                            y1=mins, y2=maxs, alpha=alpha)\n","\n","    ax.legend(columns)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def entropy(x):\n","    return -(x * torch.log(x + 1e-10)).sum(dim=-1)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"step: 100%|██████████| 235/235 [00:47<00:00,  5.65it/s, loss: 2.32853, entropy: 0.07266, likelihood: 46.43641,divergence: 0.13420, test_loss: 2.37901]\nstep: 100%|██████████| 235/235 [00:48<00:00,  5.67it/s, loss: 2.32492, entropy: 0.07238, likelihood: 46.36428,divergence: 0.13405, test_loss: 2.37444]\nstep:  37%|███▋      | 86/235 [00:17<00:27,  5.47it/s, loss: 2.32262, entropy: 0.07213, likelihood: 46.31852,divergence: 0.13393, test_loss: 2.37260]"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-fd0ffe133850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlikelihood\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdivergence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0ment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = pd.DataFrame()\n","\n","epochs_logger = tqdm(range(1, epochs + 1), desc='epoch', position=0, leave=True) \n","for epoch in epochs_logger:\n","    steps_logger = tqdm(train_loader, desc='step', total=n_batches, position=0, leave=True) \n","    for step, (x, y) in enumerate(steps_logger):\n","        model.train()\n","\n","        x, y = x.to(device), y.to(device)\n","        x = x.view(x.shape[0], -1)\n","        optimizer.zero_grad()\n","\n","        preds = []\n","        likelihood = 0\n","        divergence = 0\n","        for _ in range(samples):\n","            pred = model(x)\n","            preds.append(pred)\n","            likelihood += loss_function(pred, y)\n","            divergence += kld(model)\n","\n","        loss = (likelihood + divergence) / samples\n","        loss.backward()\n","        optimizer.step()\n","        ent = entropy(torch.stack(preds, dim=-1))\n","\n","        if step % validation_frequency == 0:\n","            # todo idk why but the behaviour is weird\n","            model.eval()\n","            test_loss = 0\n","            with torch.no_grad():\n","                for test_x, test_y in test_loader:\n","                    test_x, test_y = test_x.to(device), test_y.to(device)\n","                    test_x = test_x.view(test_x.shape[0], -1)\n","\n","                    for _ in range(samples):\n","                        pred_test = model(test_x)\n","                        test_loss += loss_function(pred_test, test_y)\n","\n","            test_loss /= (len(test_loader.dataset) / batch_size) * samples\n","            \n","        history = history.append({\n","            'epoch': epoch,\n","            'step': step,\n","            'loss': loss.item(),\n","            'entropy': ent.mean().item(),\n","            'likelihood': likelihood.item(),\n","            'divergence': divergence.item(),\n","            'test_loss': test_loss.item()\n","        }, ignore_index=True)\n","\n","        history_for_this_epoch = history.query(f'epoch == {epoch}')\n","        mean_values = history_for_this_epoch.mean(axis=0)\n","        mean_loss = mean_values['loss']\n","        mean_entropy = mean_values['entropy']\n","        mean_likelihood = mean_values['likelihood']\n","        mean_divergence = mean_values['divergence']\n","        mean_test_loss = mean_values['test_loss']\n","\n","        log_str = f'loss: {mean_loss:.5f}, entropy: {mean_entropy:.5f}, likelihood: {mean_likelihood:.5f},' + \\\n","                  f'divergence: {mean_divergence:.5f}, test_loss: {mean_test_loss:.5f}'\n","        steps_logger.set_postfix_str(log_str)\n","    epochs_logger.set_postfix_str(log_str)\n","\n","fig, axs = plt.subplots(1, 2, figsize=(5, 10))\n","plot_lines(history, ['loss', 'test_loss'], ['blue', 'orange'], axs[0], show_range=True)\n","plot_lines(history, ['likelihood', 'divergence'], ['green', 'red'], axs[1], show_range=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.to('cpu')\n","with torch.no_grad():\n","    for images, _ in test_loader:\n","        for im in images[:10]:\n","            plot_preds(im, model)\n","            plt.show()\n","        plot_preds(torch.randn(1, 28, 28), model)\n","        plt.show()\n","        break\n","\n","\n","def plot_preds(im, model):\n","    preds = [model(im.view(784)).detach().numpy()\n","             for _ in range(50)]\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(np.transpose(im, [1, 2, 0])[:, :, 0], )\n","    plt.subplot(1, 2, 2)\n","    plt.hist(np.argmax(preds, axis=1), bins=10, density=True)\n","    plt.ylim(0, 1)\n","    plt.xlim(0, 9)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}